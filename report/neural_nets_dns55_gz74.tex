\documentclass[leqno]{article}
\usepackage[top=1.2in, bottom=1in, left=1.5in, right=1.5in]{geometry}
\usepackage{tikz}
\usetikzlibrary{shapes.multipart}
\usepackage{amsmath,amssymb,amsthm,gensymb,mathtools,xfrac}
\usepackage{paralist, enumerate, multicol}
\usepackage{caption, subcaption}
\usepackage{float}
\usepackage{siunitx}
\usepackage{tabularx, booktabs}
\usepackage{parskip}
\usepackage{listings}
\usepackage{chngpage}
\usepackage[colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  citecolor=blue,
anchorcolor=blue]{hyperref}

\lstset{language=C,
  frame=single,
  breaklines=true,
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{blue}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  commentstyle=\color{gray}\ttfamily%,
  %morecomment=[l][\color{magenta}]{\#}
}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

\begin{titlepage}
\begin{center}

\textsc{\LARGE Cornell University}\\[1.5cm]

\textsc{\Large CS 4701: Practicum in Artificial Intelligence}\\[0.5cm]

% Title
\HRule \\[0.4cm]
{ \huge \bfseries Food Recognition with Deep Learning \\[0.4cm] }

\HRule \\[1.5cm]

% Author and supervisor
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Daryl Sew (dns55) \\
Cornell Computer Science '17 \\
darylsew@gmail.com \\
\vspace{0.5cm}
Alice Zhang (gz74) \\
Cornell Computer Science '17
gz74@cornell.edu \\
\vspace{0.5cm}
Instructor, Bart Selman (bs54)\\
\end{flushleft}
\end{minipage}

\vspace{1cm}

%TODO replace image here
\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{caffe.png}
\end{figure}

\vfill

% Bottom of the page
{\large December \oldstylenums{13}, \oldstylenums{2016}}

\end{center}

\end{titlepage}

\section{Problem Description}
Consider the problem of creating an artificially intelligent grocery shopper who
is able to make recipe substitutions and suggestions based on availability. Such
an agent would be highly desirable to anyone who would rather do something else
with their time than shop for groceries, and the different intelligent
components that go into this agent would have widespread applications in other
fields.

Recent advances in machine learning algorithms and computing capabilities have
enabled deep neural network architectures to surpass the state of the art
traditional machine learning classifiers in nearly every problem domain. In
particular, Convolutional Neural Networks have surpassed traditional computer
vision and machine learning techniques in many tasks, provided with large
amounts of data.

Inspired in part by the textbook grocery shopper example and in part by
\href{https://www.wired.com/2014/06/how-ibms-watson-will-make-your-meals-tastier/}{IBM's
work in recipe recommendation with Watson}, we decided to build the perception
system for food recognition, using deep learning methods in order to achieve the best
possible performance. The ability to recognize a food item in an image has
countless applications; for example, it is useful
in building cooking robots, creating an artificially intelligent grocery
shopper, automatically tracking shopper actions (i.e. Amazon Go), diet tracking
programs, and many more.

\section{High Level Design}
\subsection{Approach}
Our first attempt to train our network on resulted in very poor ($<5\%$)
accuracy, so we decided to break the problem down into more manageable chunks.

We picked K Nearest Neighbors and Support Vector Machines as baseline classifiers 
so we would be able to meaningfully evaluate the Deep Convolutional Neural
Network's performance. If we are using CNNs effectively, we should see much
better results compared to the baseline. We used the LeNet network, as it is one
of the most widely studied and used network architectures in the
field, so we knew it would be fairly easy to work with.

We started with using the baseline classifiers to classify several types of hand drawn shapes 
with no feature extraction, mimicking the MNIST dataset. We simply used the
grayscale pixel values of an image as the feature vector. We then trained the
CNN on these, evaluated the performance, and compared the results.

After this, we tried using manual feature extraction via corner detection to
improve the performance of KNN and SVMs, and tuning network parameters to
improve the performance of CNNs.

Once we had completed these sanity checks, we moved on to testing with real
datasets. We picked a dataset.


\subsection{Software Architecture}
\subsubsection{\texttt{potato.py}}
Loads model weights for a convolutional neural network and feeds
forward test inputs through the network, evaluating its performance. The network
we used was the off the shelf LeNet.
\subsubsection{\texttt{knn.py}}
Evaluates the K Nearest Neighbors classifier on test inputs. Experiments with
thresholding and corner detection as feature extractors. We chose to implement
this ourselves as we thought it would be a valuable exercise. However we did not
implement other classifiers ourselves due to time constraints. 

\subsubsection{\texttt{svm.py}}
Evaluates the Support Vector Machine classifier on test inputs. Uses the
Scikit-Learn multiclass SVM with a Radial Basis Function kernel, which allows
the SVM to make nonlinear decision boundaries and thus classify data that is not linearly separable.
\subsubsection{\texttt{train\_test\_split.py}}
Splits data into train and test data, using a library function to convert it to
the binary format that LeNet expects. 

\subsection{Data Collection Process}
TODO

\subsection{Logistics}
Training for the SVM was done on a 2015 Macbook Pro, and took a trivial ($<5$s)
amount of time.
Training for the neural network was done on an Nvidia GTX Titan.
The KNN model we used does not require an extensive training period as we
compute distances when requested.

\subsection{Theory}
\subsubsection{K Nearest Neighbors}
how does it work
\subsubsection{Support Vector Machine}
how does it work
\subsubsection{Convolutional Neural Network (LeNet)}
how does it work

We created the following network visualization via Caffe's
\texttt{draw\_net.py}.
 TODO split up image
\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{lenet.png}
\end{figure}
\subsubsection{Cross Validation}
talk about train test split and why it's needed
\section{Evaluation}
For evaluating performance, we decided to focus on multiclass precision-recall
curves, as they are a fairly holistic method of evaluating classifier
performance. The area under the curve is a simple metric to optimize, and the
curve itself effectively characterizes classifier performance in different
situations.

We are not in a position where false positives or false negatives
have different desirabilities, either, so no modification or special analyses
are required.

\subsection{Hand Drawn Data}
The following are sample images from the three classes of hand drawn images we evaluated. The network
scales the inputs to 28x28, so we present the images after scaling below. Resizing was done via the UNIX \texttt{convert} command line tool.

The left image is a potato. The right image is a triangle. The lower image is a
five point star.


\strut
\noindent\null\hfill
\includegraphics[width=5cm]{potato.png} \hfill
\includegraphics[width=5cm]{triangle.png} \hfill\null

\noindent\null\hfill\includegraphics[width=5cm]{star.png} \hfill

\subsubsection{K Nearest Neighbors}
\subsubsection{Support Vector Machine}
\begin{figure}[h!]
  \centering
  \includegraphics[width=15cm]{svm_pr_hand.png}
\end{figure}
(trained on 20 16x16 images; if time redo on 40 28x28 images. there seems to be
a bug rn)
classes correct:  [4.0, 3.0, 0.0]
total:  [5, 3, 7]
accuracy:  [ 0.8  1.   0. ]

\subsubsection{Convolutional Neural Network}

\subsection{Food Dataset}
\subsubsection{K Nearest Neighbors}
\subsubsection{Support Vector Machine}
\subsubsection{Convolutional Neural Network}

\section{Conclusion}

\section{Lessons Learned}
While the end result is lots of fun to play around with and is rather
impressive, there's a lot of work that goes into training a deep neural net. We never
thought that we would spend so much time on dataset curation and pipelining; we
thought the dataset organization and input part would be quick, and the slow
part would be finding a network architecture that is performant. Although we
didn't end up having much time to explore different network architectures this
time, budgeting more time for data munging work next time we do a project like
this would enable more exploratory data science / artificial intelligence work,
so next time we might have time to have a bit more fun.

If we could do this again, we'd also try to plan out some of the software design
in advance. We made separate scripts to handle different types of
datasets (i.e. datasets from other people, a dataset we created ourself).
However, there were actually a lot of things in common. For example, we had a
script to split the data we recorded into train and test and a separate script
to convert it to MNIST, and then we had a script to split a research dataset
into train and test and convert it to MNIST, and much of the functionality is
shared between the two.

Additionally, the process to use a different dataset with the neural network or 
integrate a different dataset into a baseline classifier
requires many intermediate steps, and those could be done in one step. If we
streamlined the pipeline it would speed up the ease of working on this a lot.

\section{Future Work}
We would love to try a novel network architecture and achieve better performance
in the future. In particular, something that is inspired by the way the human
visual system processes images of food would be interesting, and could be
grounds for publishing a paper.

On the practical side of things, some future work could be creating an ensemble
model of classifiers that will be able to pick out typical foods in a fridge.
As far as we can tell, there does not exist a dataset of fridge items, so we
would have to create a large dataset of fridge items. We could then build a
knowledge representation for recipes or attempt to use machine learning to build
a recipe recommendation on top of that.

\clearpage
\section{Appendix}
\subsection{Screenshots}
\begin{figure}[h!]
  \centering
  \includegraphics[width=15cm]{training.png}
  \caption{Training the network on a GTX Titan X. So fast!}
\end{figure}
\begin{figure}[h!]
  \centering
  \includegraphics[width=15cm]{curation_and_test.png}
  \caption{Testing the network while waiting for shell/Python scripts to curate dataset.}
\end{figure}
\subsection{Code}
Here we present an annotated listing of all of the code we wrote for this
project. The code is also available on \href{http://github.com/darylsew/potato}{GitHub}.

\section{Permissions}
Our code is under the Apache license; see
\href{http://github.com/darylsew/potato}{GitHub} for more details.

If you found our work helpful in your research, we would appreciate it if you could consider
listing us as authors. Feel free to contact us.

\section{Credits}
Thanks to the Cornell Graphics and Vision lab for donating a tiny amount of GPU
power for us to train our network. We did not have access to Nvidia GPUs, so we
would have had to spend orders of magnitude more time training on CPUs
otherwise.

Thanks to
\href{https://github.com/gskielian/JPG-PNG-to-MNIST-NN-Format/blob/master/LICENSE}{gkielian}
for the script we used to convert our PNG images into the custom binary format
the LeNet expects.

\begin{thebibliography}{9}
\bibitem{jia2014caffe}
Jia, Yangqing, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell.
\textit{Caffe: Convolutional Architecture for Fast Feature Embedding}.
arXiv preprint arXiv:1408.5093, 2014.


\bibitem{scikit-learn}
Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.
         \textit{Scikit-learn: Machine Learning in Python}. Journal of Machine
         Learning Research 12.2825-2830, 2011.

\bibitem{LeNet}
   Y. LeCun, L. D. Jackel, B. Boser, J. S. Denker, H. P. Graf, I. Guyon, D.
   Henderson, R. E. Howard, and W. Hubbard. \textit{Handwritten digit
   recognition: Applications of neural net chips and automatic learning.} IEEE Communication, pages 41-46, November 1989. invited paper.

\bibitem{Food Dataset}
 \url{http://www.site.uottawa.ca/~shervin/pubs/FoodRecognitionDataset-MadiMa.pdf}
\end{thebibliography}

\end{document}
